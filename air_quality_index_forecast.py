# -*- coding: utf-8 -*-
"""Air_Quality_Index_Forecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KKr0mWB9SaQ-3BFku3wwYRHKJocCWfy7
"""

# Commented out IPython magic to ensure Python compatibility.
# data preprocessing
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import datetime as dt
from datetime import datetime
import tensorflow.keras as keras
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard
from numpy import polyfit
import urllib.request
# %matplotlib inline

df = pd.read_csv('air_quality_ts.csv',parse_dates={'dt' : ['Date', 'Time']}, sep=" ",infer_datetime_format=True,low_memory=False, na_values=['nan','?'], index_col='dt')

df.info()

df.shape

df.columns

df_new = df[['PM2.5','PM10','CO','CO2','TEMP','HUM']]

df_new.tail(5)

# resampling so that the frequency becomes hourly and taking mean
df_new = df_new.resample('H').mean()

df_new['PM10'].plot(figsize=(8,4), color="tab:blue");
df_new['PM2.5'].plot(figsize=(8,4), color="tab:red");

len(df_new)

df_new_actual = df_new.copy()

df_new_actual.isnull().sum()

df_new_actual = df_new_actual.fillna(df_new_actual.mean())

df_new_actual.shape

df_new_actual['PM2.5'].plot(figsize=(8,4));
df_new_actual['PM10'].plot(figsize=(8,4));

X = df_new_actual.iloc[:,0:2].values
diff = list()
hours_in_the_period = 30
for i in range(hours_in_the_period, len(X)):
	value = X[i] - X[i - hours_in_the_period]
	diff.append(value)
plt.plot(diff)
plt.show()

X = df_new_actual.iloc[:,0:2]
df_daily = X.resample('D')
daily_mean = df_daily.mean()
print(daily_mean.tail())
diff1 = list()
diff2 = list()
days_in_month = 30
for i in range(days_in_month, len(daily_mean)):
  value1 = float(str(daily_mean.iloc[i:i+1,0:1]).split()[-1]) - float(str(daily_mean.iloc[i - days_in_month:i - days_in_month+1,0:1]).split()[-1])
  value2 = float(str(daily_mean.iloc[i:i+1,1:2]).split()[-1]) - float(str(daily_mean.iloc[i - days_in_month:i - days_in_month+1,1:2]).split()[-1])
  diff1.append(value1) 
  diff2.append(value2)
plt.plot(diff1)
plt.plot(diff2)
plt.show()

# fit polynomial: x^2*b1 + x*b2 + ... + bn
X = [i%24 for i in range(0, len(df_new_actual.iloc[:,0:1]))]
y = df_new_actual.iloc[:,0:2].values
degree = 1
coef = polyfit(X, y, degree)
print('Coefficients: %s' % coef)
# create curve
curve = list()
for i in range(len(X)):
	value = coef[-1]
	for d in range(degree):
		value += X[i]**(degree-d) * coef[d]
	curve.append(value)
# create seasonally adjusted
value1 = df_new_actual.iloc[:,0:1].values
diff = list()
for i in range(len(value1)):
	value = value1[i] - curve[i]
	diff.append(value)
plt.plot(diff)
plt.show()

col1, col2 = "PM2.5", "PM10"
corr = df_new_actual[col1].corr(df_new_actual[col2])
print("Correlation between ", col1, " and ", col2, "is: ", round(corr, 2))

col1, col2 = "PM2.5", "PM2.5"
corr = df_new_actual[col1].corr(df_new_actual[col2])
print( "Correlation between ", col1, " and ", col2, "is: ", round(corr, 2))

col1, col2 = "PM10", "PM2.5"
corr = df_new_actual[col1].corr(df_new_actual[col2])
print( "Correlation between ", col1, " and ", col2, "is: ", round(corr, 2))

col1, col2 = "PM10", "PM10"
corr = df_new_actual[col1].corr(df_new_actual[col2])
print( "Correlation between ", col1, " and ", col2, "is: ", round(corr, 2))

# Select features (columns) to be involved intro training and predictions
cols = list(df_new.iloc[0:1,0:2])

# Extract dates (will be used in visualization)
datelist_train = list(df_new_actual.index)
datelist_train = [date for date in datelist_train]

print('Training set shape == {}'.format(df_new_actual.iloc[:,0:2].shape))
print('All timestamps == {}'.format(len(datelist_train)))
print('Featured selected: {}'.format(cols))

# Feature Scaling
from sklearn.preprocessing import StandardScaler
training_set = df_new_actual[cols]
sc = StandardScaler()
training_set_scaled = sc.fit_transform(training_set)

sc_predict = StandardScaler()
sc_predict.fit_transform(training_set.iloc[:,0:1])

print(training_set.describe())
training_set.hist()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
log_folder= 'logs'
# %reload_ext tensorboard

df_new_actual.mean()

# Creating a data structure with 21 days timestamps and 1 output
X_train = []
y_train = []

n_future = 7   # Number of days we want top predict into the future
n_past = 96    # Number of past days we want to use to predict the future

for i in range(n_past, len(training_set_scaled) - n_future +1):
    X_train.append(training_set_scaled[i - n_past:i, 0:df_new.shape[0]])
    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])

X_train, y_train = np.array(X_train), np.array(y_train)

print('X_train shape == {}.'.format(X_train.shape))
print('y_train shape == {}.'.format(y_train.shape))

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=32, kernel_size=2,
                      padding="causal",strides=1,
                      activation='relu',
                      input_shape=[None, 2]),
  tf.keras.layers.Conv1D(filters=32, kernel_size=2,
                      padding="causal",strides=1,
                      activation='relu',
                      input_shape=[None, 2]),
  tf.keras.layers.MaxPool1D(),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),
  tf.keras.layers.LSTM(64,return_sequences=True),
])
model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Lambda(lambda x: x * 200))

optimizer = keras.optimizers.SGD(learning_rate=1.5*1e-5,momentum=0.95)
model.compile(loss=tf.keras.losses.Huber(),
             optimizer=optimizer,
             metrics=['mse','accuracy'])
from keras import backend as K
#def root_mean_squared_error(y_true, y_pred):
#        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) 
#model.compile(optimizer = "rmsprop", loss = root_mean_squared_error, metrics =["accuracy"])

model.summary()

callbacks = [TensorBoard(log_dir=log_folder, histogram_freq=1, 
 write_graph=True, write_images=True,     
 update_freq='epoch', profile_batch=2)]

history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks = callbacks)

# Generate list of sequence of days for predictions
datelist_future = pd.date_range(datelist_train[-1], periods=n_future, freq='1d').tolist()

# Convert Pandas Timestamp to Datetime object (for transformation) --> FUTURE
datelist_future_ = []
for this_timestamp in datelist_future:
    datelist_future_.append(this_timestamp.date())

datelist_train[-1]

datelist_future_

# Perform predictions
predictions_future = model.predict(X_train[-n_future:])
predictions_train = model.predict(X_train[n_past:])

# Inverse the predictions to original measurements

# ---> Special function: convert <datetime.date> to <Timestamp>
def datetime_to_timestamp(x):
    '''
        x : a given datetime value (datetime.date)
    '''
    return datetime.strptime(x.strftime('%Y%m%d'), '%Y%m%d')


y_pred_future = sc_predict.inverse_transform(predictions_future)
y_pred_train = sc_predict.inverse_transform(predictions_train)
PREDICTIONS_FUTURE = pd.DataFrame(y_pred_future, columns=['PM2.5']).set_index(pd.Series(datelist_future))
PREDICTION_TRAIN = pd.DataFrame(y_pred_train, columns=['PM2.5']).set_index(pd.Series(datelist_train[2 * n_past + n_future -1:]))

PREDICTIONS_FUTURE

PREDICTION_TRAIN

# Set plot size 
# from pylab import rcParams
plt.rcParams['figure.figsize'] = 14, 5

# Plot parameters
START_DATE_FOR_PLOTTING = '2019-07-27'

plt.plot(PREDICTIONS_FUTURE.index, PREDICTIONS_FUTURE['PM2.5'], color='r', label='Predicted Particulate matter')
plt.plot(PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:].index, PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:]['PM2.5'], color='orange', label='Training predictions')
plt.plot(df_new_actual.loc[START_DATE_FOR_PLOTTING:].index, df_new_actual.loc[START_DATE_FOR_PLOTTING:]['PM2.5'], color='b', label='Actual data')

plt.axvline(x = min(PREDICTIONS_FUTURE.index), color='green', linewidth=2, linestyle='--')

plt.grid(which='major', color='#cccccc', alpha=0.5)

plt.legend(shadow=True)
plt.title('Predcitions and Acutal Particulate Matter Vaalues', family='Arial', fontsize=12)
plt.xlabel('Timeline', family='Arial', fontsize=10)
plt.ylabel('PM 2.5', family='Arial', fontsize=10)
# plt.xticks(rotation=45, fontsize=8)
# plt.show()

import matplotlib.pyplot as plt

plt.semilogx(history.history["loss"])
plt.axis([1, 100, 0, 1])

plt.semilogx(history.history["accuracy"])
plt.axis([1, 100, 0, 1])

plt.semilogx(history.history["mse"])
plt.axis([1, 100, 0, 2])

from time import sleep
for i in range(PREDICTIONS_FUTURE.shape[0]):
  value = str(PREDICTIONS_FUTURE.iloc[i:i+1,0:1])
  valuelist=value.split()
  val = valuelist[-1]
  print(val)
  val = val.replace(' ', "%20")
  val = val.replace('\n', "%0A")
  b=urllib.request.urlopen('https://api.thingspeak.com/update?api_key=LZAJPLQ3O40YZ6FT&field1='+ val)
  sleep(15)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

