# -*- coding: utf-8 -*-
"""Air_Quality_Index_Forecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KKr0mWB9SaQ-3BFku3wwYRHKJocCWfy7
"""

# Commented out IPython magic to ensure Python compatibility.
# data preprocessing
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import tensorflow as tf
import datetime as dt
from datetime import datetime
from tensorflow import keras as keras
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard
from numpy import polyfit
from urllib import request
import streamlit
%matplotlib inline

df = pd.read_csv('air_quality_ts.csv',parse_dates={'dt' : ['Date', 'Time']}, sep=" ",infer_datetime_format=True,low_memory=False, na_values=['nan','?'], index_col='dt')

df.info()

df.shape

df.columns

df_new = df[['PM2.5','PM10','CO','CO2','TEMP','HUM']]

df_new.tail(5)

# resampling so that the frequency becomes hourly and taking mean
df_new = df_new.resample('H').mean()

df_new['PM10'].plot(figsize=(8,4), color="tab:blue");
df_new['PM2.5'].plot(figsize=(8,4), color="tab:red");

len(df_new)

df_new_actual = df_new.copy()

#df_new_actual.isnull().sum()

df_new_actual = df_new_actual.fillna(df_new_actual.mean())

#df_new_actual.shape

df_new_actual['PM2.5'].plot(figsize=(8,4));
df_new_actual['PM10'].plot(figsize=(8,4));

#X = df_new_actual.iloc[:,0:2].values
#diff = list()
#hours_in_the_period = 30
#for i in range(hours_in_the_period, len(X)):
#	value = X[i] - X[i - hours_in_the_period]
#	diff.append(value)
#plt.plot(diff)
#plt.show()

X = df_new_actual.iloc[:,0:2]
df_daily = X.resample('D')
daily_mean = df_daily.mean()
print(daily_mean.tail())
diff1 = list()
diff2 = list()
days_in_month = 30
for i in range(days_in_month, len(daily_mean)):
  value1 = float(str(daily_mean.iloc[i:i+1,0:1]).split()[-1]) - float(str(daily_mean.iloc[i - days_in_month:i - days_in_month+1,0:1]).split()[-1])
  value2 = float(str(daily_mean.iloc[i:i+1,1:2]).split()[-1]) - float(str(daily_mean.iloc[i - days_in_month:i - days_in_month+1,1:2]).split()[-1])
  diff1.append(value1) 
  diff2.append(value2)
#plt.plot(diff1)
#plt.plot(diff2)
#plt.show()

#to remove seasonality effects
# fit polynomial: x*b1 + ... + bn
X = [i%24 for i in range(0, len(df_new_actual.iloc[:,0:1]))]
y = df_new_actual.iloc[:,0:2].values
degree = 1
coef = polyfit(X, y, degree)
print('Coefficients: %s' % coef)
# create curve
curve = list()
for i in range(len(X)):
	value = coef[-1]
	for d in range(degree):
		value += X[i]**(degree-d) * coef[d]
	curve.append(value)
# create seasonally adjusted
value1 = df_new_actual.iloc[:,0:1].values
diff = list()
for i in range(len(value1)):
	value = value1[i] - curve[i]
	diff.append(value)
#plt.plot(diff)
#plt.show()
X = [i%24 for i in range(0, len(df_new_actual.iloc[:,1:2]))]
y = df_new_actual.iloc[:,0:2].values
degree = 1
coef = polyfit(X, y, degree)
print('Coefficients: %s' % coef)
# create curve
curve = list()
for i in range(len(X)):
	value = coef[-1]
	for d in range(degree):
		value += X[i]**(degree-d) * coef[d]
	curve.append(value)
# create seasonally adjusted
value2 = df_new_actual.iloc[:,1:2].values
diffn = list()
for i in range(len(value1)):
	valuex = value2[i] - curve[i]
	diffn.append(valuex)
	

# Select features (columns) to be involved intro training and predictions
cols = list(df_new.iloc[0:1,0:2])

# Extract dates (will be used in visualization)
datelist_train = list(df_new_actual.index)
datelist_train = [date for date in datelist_train]

print('Training set shape == {}'.format(df_new_actual.iloc[:,0:2].shape))
print('All timestamps == {}'.format(len(datelist_train)))
print('Featured selected: {}'.format(cols))

# Feature Scaling
from sklearn.preprocessing import StandardScaler
training_set = df_new_actual[cols]
sc = StandardScaler()
training_set_scaled = sc.fit_transform(training_set)

sc_predict = StandardScaler()
sc_predict.fit_transform(training_set.iloc[:,0:1])

print(training_set.describe())
training_set.hist()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
#log_folder= 'logs'
# %reload_ext tensorboard

df_new_actual.mean()

# Creating a data structure with 21 days timestamps and 1 output
X_train = []
y_train = []

n_future = 7   # Number of days we want top predict into the future
n_past = 96    # Number of past days we want to use to predict the future

for i in range(n_past, len(training_set_scaled) - n_future +1):
    X_train.append(training_set_scaled[i - n_past:i, 0:df_new.shape[0]])
    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])

X_train, y_train = np.array(X_train), np.array(y_train)

print('X_train shape == {}.'.format(X_train.shape))
print('y_train shape == {}.'.format(y_train.shape))

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=32, kernel_size=2,
                      padding="causal",strides=1,
                      activation='relu',
                      input_shape=[None, 2]),
  tf.keras.layers.Conv1D(filters=32, kernel_size=2,
                      padding="causal",strides=1,
                      activation='relu',
                      input_shape=[None, 2]),
  tf.keras.layers.MaxPool1D(),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),
  tf.keras.layers.LSTM(64,return_sequences=True),
])
model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Lambda(lambda x: x * 200))

optimizer = keras.optimizers.SGD(learning_rate=1.5*1e-5,momentum=0.95)
model.compile(loss=tf.keras.losses.Huber(),
             optimizer=optimizer,
             metrics=['mse','accuracy'])
from keras import backend as K
#def root_mean_squared_error(y_true, y_pred):
#        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) 
#model.compile(optimizer = "rmsprop", loss = root_mean_squared_error, metrics =["accuracy"])

model.summary()

#callbacks = [TensorBoard(log_dir=log_folder, histogram_freq=1, 
 #write_graph=True, write_images=True,     
 #update_freq='epoch', profile_batch=2)]

history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)

# Generate list of sequence of days for predictions
datelist_future = pd.date_range(datelist_train[-1], periods=n_future, freq='1d').tolist()

# Convert Pandas Timestamp to Datetime object (for transformation) --> FUTURE
datelist_future_ = []
for this_timestamp in datelist_future:
    datelist_future_.append(this_timestamp.date())

datelist_train[-1]

datelist_future_

# Perform predictions
predictions_future = model.predict(X_train[-n_future:])
predictions_train = model.predict(X_train[n_past:])

# Inverse the predictions to original measurements

# ---> Special function: convert <datetime.date> to <Timestamp>
def datetime_to_timestamp(x):
    '''
        x : a given datetime value (datetime.date)
    '''
    return datetime.strptime(x.strftime('%Y%m%d'), '%Y%m%d')


y_pred_future = sc_predict.inverse_transform(predictions_future)
y_pred_train = sc_predict.inverse_transform(predictions_train)
PREDICTIONS_FUTURE = pd.DataFrame(y_pred_future, columns=['PM2.5']).set_index(pd.Series(datelist_future))
PREDICTION_TRAIN = pd.DataFrame(y_pred_train, columns=['PM2.5']).set_index(pd.Series(datelist_train[2 * n_past + n_future -1:]))

PREDICTIONS_FUTURE

PREDICTION_TRAIN

# Set plot size 
# from pylab import rcParams
plt.rcParams['figure.figsize'] = 14, 5

# Plot parameters
START_DATE_FOR_PLOTTING = '2019-07-27'

plt.plot(PREDICTIONS_FUTURE.index, PREDICTIONS_FUTURE['PM2.5'], color='r', label='Predicted Particulate matter')
plt.plot(PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:].index, PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:]['PM2.5'], color='orange', label='Training predictions')
plt.plot(df_new_actual.loc[START_DATE_FOR_PLOTTING:].index, df_new_actual.loc[START_DATE_FOR_PLOTTING:]['PM2.5'], color='b', label='Actual data')

plt.axvline(x = min(PREDICTIONS_FUTURE.index), color='green', linewidth=2, linestyle='--')

plt.grid(which='major', color='#cccccc', alpha=0.5)

plt.legend(shadow=True)
plt.title('Predcitions and Acutal Particulate Matter Vaalues', family='Arial', fontsize=12)
plt.xlabel('Timeline', family='Arial', fontsize=10)
plt.ylabel('PM 2.5', family='Arial', fontsize=10)
# plt.xticks(rotation=45, fontsize=8)
# plt.show()


from time import sleep
for i in range(PREDICTIONS_FUTURE.shape[0]):
  value = str(PREDICTIONS_FUTURE.iloc[i:i+1,0:1])
  valuelist=value.split()
  val = valuelist[-1]
  print(val)
  val = val.replace(' ', "%20")
  val = val.replace('\n', "%0A")
  b=urllib.request.urlopen('https://api.thingspeak.com/update?api_key=LZAJPLQ3O40YZ6FT&field1='+ val)
  sleep(15)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

